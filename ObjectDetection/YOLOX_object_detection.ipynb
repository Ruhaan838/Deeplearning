{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Modeuls"
      ],
      "metadata": {
        "id": "P8Frcneqmzlj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JTv4Ac5ZW4JE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Conv2D,BatchNormalization,LeakyReLU,Dense,Flatten,Reshape,Dropout\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler as LRS\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Prepration"
      ],
      "metadata": {
        "id": "XqhSSKZYm3ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "dY3JphBfXGjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d huanghanchina/pascal-voc-2012"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-dKPmz1XEhk",
        "outputId": "6cff6ed5-accc-4ba5-ed23-f4254d5674d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pascal-voc-2012.zip to /content\n",
            "100% 3.63G/3.63G [03:08<00:00, 24.3MB/s]\n",
            "100% 3.63G/3.63G [03:08<00:00, 20.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/pascal-voc-2012.zip' -d '/content/dataset/'"
      ],
      "metadata": {
        "id": "bF_5p66WXg-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_list=['2007_000027.jpg','2007_000032.jpg','2007_000033.jpg','2007_000039.jpg','2007_000042.jpg','2007_000061.jpg',\n",
        "          '2007_000063.jpg','2007_000068.jpg','2007_000121.jpg','2007_000123.jpg','2007_000129.jpg','2007_000170.jpg',\n",
        "          '2007_000175.jpg','2007_000187.jpg','2007_000241.jpg','2007_000243.jpg','2007_000250.jpg','2007_000256.jpg',\n",
        "          '2007_000272.jpg','2007_000323.jpg','2007_000332.jpg','2007_000333.jpg','2007_000346.jpg','2007_000363.jpg',\n",
        "          '2007_000364.jpg','2007_000392.jpg','2007_000423.jpg','2007_000452.jpg','2007_000464.jpg','2007_000480.jpg',\n",
        "          '2007_000491.jpg','2007_000504.jpg','2007_000515.jpg','2007_000528.jpg','2007_000529.jpg','2007_000549.jpg',\n",
        "          '2007_000559.jpg','2007_000572.jpg','2007_000584.jpg','2007_000629.jpg','2007_000636.jpg','2007_000645.jpg',\n",
        "          '2007_000648.jpg','2007_000661.jpg','2007_000663.jpg','2007_000664.jpg','2007_000676.jpg','2007_000713.jpg',\n",
        "          '2007_000720.jpg','2007_000727.jpg','2007_000733.jpg','2007_000738.jpg','2007_000762.jpg','2007_000768.jpg',\n",
        "          '2007_000783.jpg','2007_000793.jpg','2007_000799.jpg','2007_000804.jpg','2007_000807.jpg','2007_000822.jpg',\n",
        "          '2007_001299.jpg','2007_001311.jpg','2007_001321.jpg','2007_001340.jpg']"
      ],
      "metadata": {
        "id": "P-9tKmRaXsxZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Dataset"
      ],
      "metadata": {
        "id": "nVWu8ESLnDo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images='/content/dataset/VOC2012/JPEGImages/'\n",
        "train_maps='/content/dataset/VOC2012/Annotations/'\n",
        "\n",
        "val_images='/content/dataset/VOC2012/ValJPEGImages/'\n",
        "val_maps='/content/dataset/VOC2012/ValAnnotations/'\n",
        "\n",
        "classes=['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable',\n",
        "         'dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
        "\n",
        "B=2\n",
        "N_CLASSES=len(classes)\n",
        "H,W =224,224\n",
        "SPLIT_SIZE=H//32\n",
        "print(SPLIT_SIZE)\n",
        "N_EPOCHS=135\n",
        "BATCH_SIZE=32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJtW1bbBYcCG",
        "outputId": "22aeb959-a43c-40cd-9122-fed97d72755e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/dataset/VOC2012/ValJPEGImages/\n",
        "!mkdir /content/dataset/VOC2012/ValAnnotations/"
      ],
      "metadata": {
        "id": "D1c0Q48tf3we"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in val_list:\n",
        "  shutil.move(train_maps+name[:-3]+\"xml\", val_maps+name[:-3]+\"xml\")"
      ],
      "metadata": {
        "id": "uy0Lkz_Pf59b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in val_list:\n",
        "  shutil.move(train_images+name, val_images+name)"
      ],
      "metadata": {
        "id": "2TQ1XC1jf7g8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prosses The XML files"
      ],
      "metadata": {
        "id": "tMzON8KlnMcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_xml(filename):\n",
        "  tree = ET.parse(filename)\n",
        "  root = tree.getroot()\n",
        "  size_tree = root.find('size')\n",
        "  height = float(size_tree.find('height').text)\n",
        "  width = float(size_tree.find('width').text)\n",
        "  bounding_boxes=[]\n",
        "  for object_tree in root.findall('object'):\n",
        "    for bounding_box in object_tree.iter('bndbox'):\n",
        "      xmin = (float(bounding_box.find('xmin').text))\n",
        "      ymin = (float(bounding_box.find('ymin').text))\n",
        "      xmax = (float(bounding_box.find('xmax').text))\n",
        "      ymax = (float(bounding_box.find('ymax').text))\n",
        "      break\n",
        "    class_name = object_tree.find('name').text\n",
        "    class_dict={classes[i]:i for i in range(len(classes))}\n",
        "    bounding_box = [\n",
        "        (xmin+xmax)/(2*width),(ymin+ymax)/(2*height),(xmax-xmin)/width,\n",
        "        (ymax-ymin)/height,class_dict[class_name]]\n",
        "    bounding_boxes.append(bounding_box)\n",
        "  return tf.convert_to_tensor(bounding_boxes)"
      ],
      "metadata": {
        "id": "yiCU5msnf9CU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_xml(val_maps+\"2007_000032.xml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8sQSZrvf-4U",
        "outputId": "f0c72cf1-f8fc-4331-f9b6-cb098548357e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[ 0.479     ,  0.4644128 ,  0.542     ,  0.37366548,  0.        ],\n",
              "       [ 0.33      ,  0.37544483,  0.128     ,  0.12455516,  0.        ],\n",
              "       [ 0.408     ,  0.727758  ,  0.036     ,  0.17437722, 14.        ],\n",
              "       [ 0.07      ,  0.7597865 ,  0.036     ,  0.17437722, 14.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output(bounding_boxes):\n",
        "  output_label=np.zeros((SPLIT_SIZE,SPLIT_SIZE,N_CLASSES+5))\n",
        "  for b in range(len(bounding_boxes)):\n",
        "    grid_x=bounding_boxes[...,b,0]*SPLIT_SIZE\n",
        "    grid_y=bounding_boxes[...,b,1]*SPLIT_SIZE\n",
        "    i=int(grid_x)\n",
        "    j=int(grid_y)\n",
        "\n",
        "    output_label[i,j,0:5]=[1.,grid_x%1,grid_y%1,bounding_boxes[...,b,2],bounding_boxes[...,b,3]]\n",
        "    output_label[i,j,5+int(bounding_boxes[...,b,4])]=1.\n",
        "\n",
        "  return tf.convert_to_tensor(output_label,tf.float32)"
      ],
      "metadata": {
        "id": "CgfTN4H4gAdc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_output(preprocess_xml(val_maps+\"2007_000032.xml\"),)[3][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPoyGxFtgB7U",
        "outputId": "2f9784f6-cace-407f-bea9-83913ae19c11"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
              "array([1.        , 0.35299993, 0.25088978, 0.542     , 0.37366548,\n",
              "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Dataset"
      ],
      "metadata": {
        "id": "2QB6_U1AnULL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im_paths=[]\n",
        "xml_paths=[]\n",
        "\n",
        "val_im_paths=[]\n",
        "val_xml_paths=[]\n",
        "\n",
        "\n",
        "for i in os.listdir(train_maps):\n",
        "\n",
        "  im_paths.append(train_images+i[:-3]+'jpg')\n",
        "  xml_paths.append(train_maps+i)\n",
        "\n",
        "for i in os.listdir(val_maps):\n",
        "\n",
        "  val_im_paths.append(val_images+i[:-3]+'jpg')\n",
        "  val_xml_paths.append(val_maps+i)\n",
        "\n",
        "print(len(im_paths),len(xml_paths))\n",
        "print(len(val_im_paths),len(val_xml_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNKIlw4SgDaU",
        "outputId": "e6fe2dd8-c779-4165-8618-37fe109abe4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17061 17061\n",
            "64 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=tf.data.Dataset.from_tensor_slices((im_paths,xml_paths))\n",
        "val_dataset=tf.data.Dataset.from_tensor_slices((val_im_paths,val_xml_paths))"
      ],
      "metadata": {
        "id": "e6uu5OwVgE-c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in val_dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpYyPHwcgGbs",
        "outputId": "bc2dfd48-6c3f-4fa1-9290-bc145513158a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'/content/dataset/VOC2012/ValJPEGImages/2007_000241.jpg'>, <tf.Tensor: shape=(), dtype=string, numpy=b'/content/dataset/VOC2012/ValAnnotations/2007_000241.xml'>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting an images bounding box"
      ],
      "metadata": {
        "id": "TQY63syInqrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_imbboxes(im_path,xml_path):\n",
        "  img=tf.io.decode_jpeg(tf.io.read_file(im_path))\n",
        "  img=tf.cast(tf.image.resize(img, [H,W]),dtype=tf.float32)\n",
        "\n",
        "  bboxes=tf.numpy_function(func=preprocess_xml, inp=[xml_path], Tout=tf.float32)\n",
        "  return img,bboxes"
      ],
      "metadata": {
        "id": "qw7KX_regHwU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=train_dataset.map(get_imbboxes)\n",
        "val_dataset=val_dataset.map(get_imbboxes)"
      ],
      "metadata": {
        "id": "0NXVagf8gJhd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in train_dataset.skip(2):\n",
        "  print(i.shape,j)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWykWHzzgMvk",
        "outputId": "66430ef6-3c28-4d10-d422-8fe971909467"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3) tf.Tensor([[ 0.40933332  0.907       0.15733333  0.186      14.        ]], shape=(1, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imwrite('out_1.jpg',np.array(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVU429GmgN-U",
        "outputId": "a39d5f00-a544-4ddb-d2ad-5e2b80678054"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmantation"
      ],
      "metadata": {
        "id": "IEeHOTRFnyrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = A.Compose([\n",
        "    A.Resize(H,W),\n",
        "    A.RandomCrop(\n",
        "         width=np.random.randint(int(0.9*W),W),\n",
        "         height=np.random.randint(int(0.9*H),H), p=0.5),\n",
        "    A.RandomScale(scale_limit=0.1, interpolation=cv2.INTER_LANCZOS4,p=0.5),\n",
        "    A.HorizontalFlip(p=0.5,),\n",
        "    A.Resize(H,W),\n",
        "\n",
        "], bbox_params=A.BboxParams(format='yolo', ))"
      ],
      "metadata": {
        "id": "MHxYJrpUgPWV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aug_albument(image,bboxes):\n",
        "  augmented=transforms(image=image,bboxes=bboxes)\n",
        "  return [tf.convert_to_tensor(augmented[\"image\"],dtype=tf.float32),\n",
        "          tf.convert_to_tensor(augmented[\"bboxes\"],dtype=tf.float32)]"
      ],
      "metadata": {
        "id": "eHKSd4UFghFK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(image,bboxes):\n",
        "    aug= tf.numpy_function(func=aug_albument, inp=[image,bboxes], Tout=(tf.float32,tf.float32))\n",
        "    return aug[0],aug[1]"
      ],
      "metadata": {
        "id": "myst5Cp1gl2l"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=train_dataset.map(process_data)"
      ],
      "metadata": {
        "id": "RpP5D8HjgnhF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in train_dataset.skip(2):\n",
        "  print(i.shape,j)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TDlOTM3gpIF",
        "outputId": "04b4a6b1-04b0-4ded-a7d4-34aefd59c1da"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3) tf.Tensor([[ 0.5950198   0.91066664  0.16092542  0.17866667 14.        ]], shape=(1, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprosses"
      ],
      "metadata": {
        "id": "7F2mPH2dn2yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_augment(img,y):\n",
        "  img = tf.image.random_brightness(img, max_delta=50.)\n",
        "  img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "  img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "  #img = tf.image.random_hue(img, max_delta=0.5 )\n",
        "  img = tf.clip_by_value(img, 0, 255)\n",
        "  labels=tf.numpy_function(func=generate_output, inp=[y], Tout=(tf.float32))\n",
        "  return img,labels"
      ],
      "metadata": {
        "id": "B9YpYWupgqnu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img,y):\n",
        "  img = tf.cast(tf.image.resize(img, size=[H, W]), dtype=tf.float32)\n",
        "\n",
        "  labels=tf.numpy_function(func=generate_output, inp=[y], Tout=(tf.float32))\n",
        "  return img,labels"
      ],
      "metadata": {
        "id": "l7RCOC-WgtMN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=train_dataset.map(preprocess_augment)\n",
        "val_dataset=val_dataset.map(preprocess)"
      ],
      "metadata": {
        "id": "ATuNDJK2gvEF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=(\n",
        "  train_dataset.\n",
        "  batch(BATCH_SIZE).\n",
        "  prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "GoIRkX8hgx3t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset=(\n",
        "  val_dataset.\n",
        "  batch(BATCH_SIZE).\n",
        "  prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "ORjDc9RygzSd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in train_dataset.take(1):\n",
        "  print(i.shape,j)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epunROCpg0k9",
        "outputId": "686e6f5a-06b6-4755-8acf-7bbd90ae7755"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) tf.Tensor(\n",
            "[[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.13317496 0.343135   ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.7494795  0.7884323  ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.866411   0.807267   ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.9260639  0.7695976  ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.6229404  0.05387402 ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.24105948 0.73192775 ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.4709999  0.27395204 ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], shape=(32, 7, 7, 25), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model (`YOLOX`)"
      ],
      "metadata": {
        "id": "FmnOn81Dn7Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_FILTERS=512\n",
        "OUTPUT_DIM=N_CLASSES+5*B"
      ],
      "metadata": {
        "id": "q6Ox625Fg2S1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=tf.keras.applications.efficientnet.EfficientNetB1(\n",
        "    weights='imagenet',\n",
        "    input_shape=(H,W,3),\n",
        "    include_top=False,\n",
        ")\n",
        "base_model.trainable=False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZAcozZ_g5DN",
        "outputId": "cd42fdc7-be44-4784-826e-7988cc0a4e0f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "27018416/27018416 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([\n",
        "  base_model,\n",
        "  Conv2D(NUM_FILTERS,(3,3), padding = 'same',kernel_initializer='he_normal',),\n",
        "  BatchNormalization(),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Conv2D(NUM_FILTERS,(3,3),padding = 'same',kernel_initializer='he_normal',),\n",
        "  BatchNormalization(),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Conv2D(NUM_FILTERS,(3,3),padding = 'same',kernel_initializer='he_normal',),\n",
        "  BatchNormalization(),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Conv2D(NUM_FILTERS,(3,3),padding = 'same',kernel_initializer='he_normal',),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Flatten(),\n",
        "\n",
        "  Dense(NUM_FILTERS,kernel_initializer='he_normal',),\n",
        "  BatchNormalization(),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Dropout(0.5),\n",
        "\n",
        "  Dense(SPLIT_SIZE*SPLIT_SIZE*OUTPUT_DIM,activation='sigmoid'),\n",
        "\n",
        "  Reshape((SPLIT_SIZE,SPLIT_SIZE,OUTPUT_DIM)),\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNvAthZ5g6XU",
        "outputId": "f87c13e6-b20a-4966-9004-58b6ac7842a9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb1 (Functional  (None, 7, 7, 1280)        6575239   \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 7, 7, 512)         5898752   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 7, 7, 512)         2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 7, 7, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 7, 7, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1470)              754110    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 30)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33161285 (126.50 MB)\n",
            "Trainable params: 26581950 (101.40 MB)\n",
            "Non-trainable params: 6579335 (25.10 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computer IOU (`intersection over union`)"
      ],
      "metadata": {
        "id": "KXyQ4Pf9oDMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(boxes1, boxes2):\n",
        "    boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
        "                         boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
        "                         boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
        "                         boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
        "                        axis=-1)\n",
        "\n",
        "    boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
        "                         boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
        "                         boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
        "                         boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
        "                        axis=-1)\n",
        "    lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
        "    rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
        "\n",
        "    intersection = tf.maximum(0.0, rd - lu)\n",
        "    inter_square = intersection[..., 0] * intersection[..., 1]\n",
        "\n",
        "    square1 = boxes1[..., 2] * boxes1[..., 3]\n",
        "    square2 = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "    union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
        "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)"
      ],
      "metadata": {
        "id": "qbXwzsHBg98O"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Loss for YOLO"
      ],
      "metadata": {
        "id": "OYjIECg3oWIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def difference(x,y):\n",
        "  return tf.reduce_sum(tf.square(y-x))"
      ],
      "metadata": {
        "id": "IMln0Xq8hAS9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_loss(y_true, y_pred):\n",
        "  target = y_true[...,0]\n",
        "\n",
        "  ###################### OBject Loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred, tf.where(target[:]==1))\n",
        "  y_target_extract = tf.gather_nd(y_true, tf.where(target[:]==1))\n",
        "\n",
        "  rescaler = tf.where(target[:]==1)*SPLIT_SIZE\n",
        "  upscaler_1 = tf.concat([rescaler[:,1:],tf.zeros([len(rescaler),2], dtype=tf.int64)],axis=-1)\n",
        "\n",
        "  target_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
        "                       repeats=[len(rescaler)], axis=0)*tf.cast(y_target_extract[...,1:5], dtype = tf.float32)\n",
        "  pred_1_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
        "                      repeats=[len(rescaler)], axis=0)*tf.cast(y_pred_extract[...,1:5], dtype = tf.float32)\n",
        "  pred_2_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
        "                      repeats=[len(rescaler)], axis=0)*tf.cast(y_pred_extract[...,6:10], dtype = tf.float32)\n",
        "\n",
        "  target_orig = tf.cast(upscaler_1, dtype = tf.float32)+target_upscaler_2\n",
        "  pred_1_orig = tf.cast(upscaler_1, dtype = tf.float32)+pred_1_upscaler_2\n",
        "  pred_2_orig = tf.cast(upscaler_1, dtype = tf.float32)+pred_2_upscaler_2\n",
        "\n",
        "  mask =tf.cast(tf.math.greater(compute_iou(target_orig,pred_2_orig),\n",
        "                                         compute_iou(target_orig,pred_1_orig)),dtype=tf.int32)\n",
        "\n",
        "  y_pred_joined=tf.transpose(tf.concat([tf.expand_dims(y_pred_extract[...,0],axis=0),\n",
        "                        tf.expand_dims(y_pred_extract[...,5],axis=0)],axis=0))\n",
        "\n",
        "  obj_pred = tf.gather_nd(y_pred_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "\n",
        "  object_loss = difference(tf.cast(obj_pred,dtype =tf.float32)\n",
        "                            ,tf.cast(tf.ones([len(rescaler)]),dtype=tf.float32))\n",
        "\n",
        "  ####################### For No object\n",
        "  y_pred_extract = tf.gather_nd(y_pred[...,0:B*5], tf.where(target[:]==0))\n",
        "  y_target_extract = tf.zeros(len(y_pred_extract))\n",
        "\n",
        "  no_object_loss_1 = difference(tf.cast(y_pred_extract[...,0],dtype =tf.float32)\n",
        "                            ,tf.cast(y_target_extract,dtype=tf.float32))\n",
        "\n",
        "  no_object_loss_2 = difference(tf.cast(y_pred_extract[...,5],dtype =tf.float32)\n",
        "                            ,tf.cast(y_target_extract,dtype=tf.float32))\n",
        "\n",
        "  no_object_loss = no_object_loss_1+no_object_loss_2\n",
        "\n",
        "  ######################## For OBject class loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred[...,10:],tf.where(target[:]==1))\n",
        "  class_extract = tf.gather_nd(y_true[...,5:],tf.where(target[:]==1))\n",
        "\n",
        "  class_loss = difference(tf.cast(y_pred_extract,dtype =tf.float32)\n",
        "                                ,tf.cast(class_extract,dtype=tf.float32))\n",
        "\n",
        "  ######################### For object bounding box loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred[...,0:B*5], tf.where(target[:]==1))\n",
        "  centre_joined=tf.stack([y_pred_extract[...,1:3],y_pred_extract[...,6:8]],axis=1)\n",
        "  centre_pred = tf.gather_nd(centre_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "  centre_target = tf.gather_nd(y_true[...,1:3], tf.where(target[:]==1))\n",
        "\n",
        "  centre_loss = difference(centre_pred,centre_target)\n",
        "\n",
        "  size_joined=tf.stack([y_pred_extract[...,3:5],y_pred_extract[...,8:10]],axis=1)\n",
        "\n",
        "  size_pred = tf.gather_nd(size_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "  size_target = tf.gather_nd(y_true[...,3:5], tf.where(target[:]==1))\n",
        "\n",
        "  size_loss = difference(tf.math.sqrt(tf.math.abs(size_pred)),tf.math.sqrt(tf.math.abs(size_target)))\n",
        "  box_loss = centre_loss+size_loss\n",
        "\n",
        "  lambda_coord = 5.0\n",
        "  lambda_no_obj = 0.5\n",
        "\n",
        "  loss = object_loss + (lambda_no_obj*no_object_loss)+ tf.cast(lambda_coord*box_loss,dtype=tf.float32)+ tf.cast(class_loss,dtype=tf.float32)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "giv2crjxhB0F"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Callbacks"
      ],
      "metadata": {
        "id": "KNjZonEmoyer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath='/content/drive/MyDrive/Bang/yolo_efficientnet_b1_new.h5'\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "wRg18WKEhDIV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 40:\n",
        "    return 1e-3\n",
        "  elif epoch>=40 and epoch<80:\n",
        "    return 5e-4\n",
        "  else:\n",
        "    return 1e-4"
      ],
      "metadata": {
        "id": "6l4vxcjXhF-l"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "xgm5LfjHhHlP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile the Model"
      ],
      "metadata": {
        "id": "Y5IYKWlOo3gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss=yolo_loss,\n",
        "  optimizer=Adam(1e-3),\n",
        ")"
      ],
      "metadata": {
        "id": "kmv4yAFOhI1u"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "_BpenmAQo6K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=val_dataset,\n",
        "  verbose=1,\n",
        "  epochs=135,\n",
        "  callbacks = [lr_callback,callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEES877ShKDu",
        "outputId": "d6967f23-7d98-49c6-aa31-4ee475c02729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/135\n",
            "534/534 [==============================] - 241s 421ms/step - loss: 177.9240 - val_loss: 187.6128 - lr: 0.0010\n",
            "Epoch 2/135\n",
            "534/534 [==============================] - 218s 408ms/step - loss: 153.8086 - val_loss: 174.7513 - lr: 0.0010\n",
            "Epoch 3/135\n",
            "534/534 [==============================] - 220s 411ms/step - loss: 143.8725 - val_loss: 164.2020 - lr: 0.0010\n",
            "Epoch 4/135\n",
            "534/534 [==============================] - 235s 441ms/step - loss: 136.7285 - val_loss: 157.3875 - lr: 0.0010\n",
            "Epoch 5/135\n",
            "534/534 [==============================] - 218s 408ms/step - loss: 130.0602 - val_loss: 150.6452 - lr: 0.0010\n",
            "Epoch 6/135\n",
            "534/534 [==============================] - 201s 376ms/step - loss: 125.6392 - val_loss: 145.1160 - lr: 0.0010\n",
            "Epoch 7/135\n",
            "534/534 [==============================] - 198s 370ms/step - loss: 121.1968 - val_loss: 146.7338 - lr: 0.0010\n",
            "Epoch 8/135\n",
            "534/534 [==============================] - 199s 372ms/step - loss: 117.3196 - val_loss: 145.1351 - lr: 0.0010\n",
            "Epoch 9/135\n",
            "534/534 [==============================] - 201s 377ms/step - loss: 113.9138 - val_loss: 143.1046 - lr: 0.0010\n",
            "Epoch 10/135\n",
            "534/534 [==============================] - 203s 380ms/step - loss: 110.5582 - val_loss: 140.7593 - lr: 0.0010\n",
            "Epoch 11/135\n",
            "534/534 [==============================] - 202s 378ms/step - loss: 107.4832 - val_loss: 138.4482 - lr: 0.0010\n",
            "Epoch 12/135\n",
            "534/534 [==============================] - 202s 378ms/step - loss: 104.5837 - val_loss: 137.6765 - lr: 0.0010\n",
            "Epoch 13/135\n",
            "534/534 [==============================] - 202s 379ms/step - loss: 102.1086 - val_loss: 136.1142 - lr: 0.0010\n",
            "Epoch 14/135\n",
            "534/534 [==============================] - 201s 376ms/step - loss: 99.8679 - val_loss: 132.1486 - lr: 0.0010\n",
            "Epoch 15/135\n",
            "534/534 [==============================] - 200s 375ms/step - loss: 97.8691 - val_loss: 133.9321 - lr: 0.0010\n",
            "Epoch 16/135\n",
            "534/534 [==============================] - 201s 376ms/step - loss: 95.4784 - val_loss: 132.1852 - lr: 0.0010\n",
            "Epoch 17/135\n",
            "534/534 [==============================] - 198s 372ms/step - loss: 93.3807 - val_loss: 137.5414 - lr: 0.0010\n",
            "Epoch 18/135\n",
            "534/534 [==============================] - 198s 372ms/step - loss: 91.5137 - val_loss: 134.3294 - lr: 0.0010\n",
            "Epoch 19/135\n",
            "534/534 [==============================] - 202s 377ms/step - loss: 90.0109 - val_loss: 131.4875 - lr: 0.0010\n",
            "Epoch 20/135\n",
            "534/534 [==============================] - 199s 372ms/step - loss: 87.8895 - val_loss: 131.7446 - lr: 0.0010\n",
            "Epoch 21/135\n",
            "534/534 [==============================] - 201s 376ms/step - loss: 86.3260 - val_loss: 130.5869 - lr: 0.0010\n",
            "Epoch 22/135\n",
            "534/534 [==============================] - 199s 372ms/step - loss: 84.5619 - val_loss: 131.7292 - lr: 0.0010\n",
            "Epoch 23/135\n",
            "534/534 [==============================] - 204s 383ms/step - loss: 83.3590 - val_loss: 129.4615 - lr: 0.0010\n",
            "Epoch 24/135\n",
            "534/534 [==============================] - 201s 377ms/step - loss: 81.9221 - val_loss: 128.8796 - lr: 0.0010\n",
            "Epoch 25/135\n",
            "534/534 [==============================] - 199s 373ms/step - loss: 80.3310 - val_loss: 132.4711 - lr: 0.0010\n",
            "Epoch 26/135\n",
            "534/534 [==============================] - 197s 369ms/step - loss: 78.8700 - val_loss: 130.6749 - lr: 0.0010\n",
            "Epoch 27/135\n",
            "534/534 [==============================] - 198s 370ms/step - loss: 77.5680 - val_loss: 131.2586 - lr: 0.0010\n",
            "Epoch 28/135\n",
            "534/534 [==============================] - 197s 369ms/step - loss: 76.2206 - val_loss: 130.9334 - lr: 0.0010\n",
            "Epoch 29/135\n",
            "534/534 [==============================] - 199s 372ms/step - loss: 75.0494 - val_loss: 133.1573 - lr: 0.0010\n",
            "Epoch 30/135\n",
            "534/534 [==============================] - 198s 371ms/step - loss: 74.0992 - val_loss: 131.6123 - lr: 0.0010\n",
            "Epoch 31/135\n",
            "534/534 [==============================] - 197s 368ms/step - loss: 72.8155 - val_loss: 132.6550 - lr: 0.0010\n",
            "Epoch 32/135\n",
            "534/534 [==============================] - 196s 368ms/step - loss: 71.5255 - val_loss: 134.2098 - lr: 0.0010\n",
            "Epoch 33/135\n",
            "534/534 [==============================] - 196s 367ms/step - loss: 70.5562 - val_loss: 132.2090 - lr: 0.0010\n",
            "Epoch 34/135\n",
            "534/534 [==============================] - 198s 370ms/step - loss: 69.7770 - val_loss: 132.0115 - lr: 0.0010\n",
            "Epoch 35/135\n",
            "534/534 [==============================] - 199s 372ms/step - loss: 68.8316 - val_loss: 135.0339 - lr: 0.0010\n",
            "Epoch 36/135\n",
            "534/534 [==============================] - 199s 373ms/step - loss: 68.1715 - val_loss: 136.4707 - lr: 0.0010\n",
            "Epoch 37/135\n",
            "534/534 [==============================] - 198s 372ms/step - loss: 66.8634 - val_loss: 131.8757 - lr: 0.0010\n",
            "Epoch 38/135\n",
            "534/534 [==============================] - 197s 368ms/step - loss: 66.2140 - val_loss: 131.1995 - lr: 0.0010\n",
            "Epoch 39/135\n",
            "534/534 [==============================] - 198s 370ms/step - loss: 64.9792 - val_loss: 132.6576 - lr: 0.0010\n",
            "Epoch 40/135\n",
            "534/534 [==============================] - 198s 372ms/step - loss: 64.4336 - val_loss: 129.5910 - lr: 0.0010\n",
            "Epoch 41/135\n",
            "534/534 [==============================] - 203s 379ms/step - loss: 61.3114 - val_loss: 128.8338 - lr: 5.0000e-04\n",
            "Epoch 42/135\n",
            "534/534 [==============================] - 200s 375ms/step - loss: 59.1839 - val_loss: 130.4852 - lr: 5.0000e-04\n",
            "Epoch 43/135\n",
            "534/534 [==============================] - 202s 378ms/step - loss: 57.7907 - val_loss: 129.1371 - lr: 5.0000e-04\n",
            "Epoch 44/135\n",
            "534/534 [==============================] - 205s 383ms/step - loss: 56.9462 - val_loss: 133.1898 - lr: 5.0000e-04\n",
            "Epoch 45/135\n",
            "506/534 [===========================>..] - ETA: 10s - loss: 56.0868"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-2I4-oVhMbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}